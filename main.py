# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ymXaaP9OJ9n6au8G60_JvogK2FKhLUq5
"""

!pip install timm torch torchvision pandas scikit-learn matplotlib seaborn openpyxl

!unzip train.zip

import os
import time
import random
from pathlib import Path
import pandas as pd
import numpy as np
from PIL import Image

import torch
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader, random_split
from torchvision import transforms
import timm

from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns
import json
import argparse

DATA_DIR = Path("train")
LABEL_CSV = Path("train.csv")
OUTPUT_DIR = Path("outputs")
OUTPUT_DIR.mkdir(exist_ok=True)
RANDOM_SEED = 42
BATCH_SIZE = 32
NUM_WORKERS = 2
NUM_EPOCHS = 12
LR = 2e-4
IMG_SIZE = 224
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
MODEL_NAMES = ["vit_base_patch16_224", "swin_tiny_patch4_window7_224"]
NUM_CLASSES = None

torch.manual_seed(RANDOM_SEED)
np.random.seed(RANDOM_SEED)
random.seed(RANDOM_SEED)

def read_label_file(path):
    if str(path).lower().endswith((".xls", ".xlsx")):
        df = pd.read_excel(path)
    else:
        df = pd.read_csv(path)
    df_columns = [c.lower() for c in df.columns]
    possible_fname_cols = ['filename', 'file', 'file_name', 'image', 'image_id', 'id', 'fname', 'name']
    possible_label_cols = ['label', 'class', 'category', 'category_name', 'target']
    fname_col = None
    label_col = None
    for c in df.columns:
        lc = c.lower()
        if any(p in lc for p in possible_fname_cols) and fname_col is None:
            fname_col = c
        if any(p in lc for p in possible_label_cols) and label_col is None:
            label_col = c
    if fname_col is None:
        fname_col = df.columns[0]
    if label_col is None:
        if len(df.columns) >= 2:
            label_col = df.columns[1]
        else:
            raise ValueError("Tidak menemukan kolom label di CSV/Excel")
    df = df[[fname_col, label_col]].rename(columns={fname_col: "filename", label_col: "label"})
    return df

# Dataset class: reads image files from DATA_DIR using filenames in csv
class FoodDataset(Dataset):
    def __init__(self, df, images_dir, transforms=None, extension_priority=[".jpg", ".jpeg", ".png"]):
        """
        df: dataframe with columns 'filename' and 'label'
        images_dir: Path to folder containing images
        """
        self.df = df.reset_index(drop=True)
        self.images_dir = Path(images_dir)
        self.transforms = transforms
        self.extension_priority = extension_priority
        self.samples = []
        for _, row in self.df.iterrows():
            fname = str(row['filename'])
            candidate = self.images_dir / fname
            if candidate.exists():
                self.samples.append((str(candidate), row['label']))
                continue
            found = False
            for ext in self.extension_priority:
                candidate = self.images_dir / (fname + ext)
                if candidate.exists():
                    self.samples.append((str(candidate), row['label']))
                    found = True
                    break
            if found:
                continue
            matches = list(self.images_dir.glob(f"*{fname}*"))
            if matches:
                self.samples.append((str(matches[0]), row['label']))
            else:
                self.samples.append((str(self.images_dir / fname), row['label']))

    def __len__(self):
        return len(self.samples)

    def __getitem__(self, idx):
        path, label = self.samples[idx]
        img = Image.open(path).convert("RGB")
        if self.transforms:
            img = self.transforms(img)
        return img, label

    def encode_labels(df):
      labels = sorted(df['label'].unique())
      label2idx = {l: i for i, l in enumerate(labels)}
      idx2label = {i: l for l, i in label2idx.items()}
      df['label_idx'] = df['label'].map(label2idx)
      return df, label2idx, idx2label

train_transforms = transforms.Compose([
    transforms.Resize((IMG_SIZE, IMG_SIZE)),
    transforms.RandomHorizontalFlip(),
    transforms.RandomRotation(10),
    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.02),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406],
                         std=[0.229, 0.224, 0.225]),
])

val_transforms = transforms.Compose([
    transforms.Resize((IMG_SIZE, IMG_SIZE)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406],
                         std=[0.229, 0.224, 0.225]),
])

def train_one_epoch(model, optimizer, scheduler, dataloader, device):
    model.train()
    total_loss = 0.0
    correct = 0
    total = 0
    criterion = nn.CrossEntropyLoss()
    for imgs, labels in dataloader:
        imgs = imgs.to(device)
        labels = labels.to(device).long()
        optimizer.zero_grad()
        outputs = model(imgs)
        if isinstance(outputs, tuple):
            outputs = outputs[0]
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
        if scheduler is not None:
            scheduler.step()
        total_loss += loss.item() * imgs.size(0)
        preds = outputs.argmax(dim=1)
        correct += (preds == labels).sum().item()
        total += imgs.size(0)
    return total_loss / total, correct / total

def evaluate(model, dataloader, device):
    model.eval()
    all_preds = []
    all_labels = []
    criterion = nn.CrossEntropyLoss()
    total_loss = 0.0
    total = 0
    with torch.no_grad():
        for imgs, labels in dataloader:
            imgs = imgs.to(device)
            labels = labels.to(device).long()
            outputs = model(imgs)
            if isinstance(outputs, tuple):
                outputs = outputs[0]
            loss = criterion(outputs, labels)
            total_loss += loss.item() * imgs.size(0)
            preds = outputs.argmax(dim=1).cpu().numpy()
            all_preds.extend(preds.tolist())
            all_labels.extend(labels.cpu().numpy().tolist())
            total += imgs.size(0)
    acc = accuracy_score(all_labels, all_preds)
    prec, rec, f1, _ = precision_recall_fscore_support(all_labels, all_preds, average=None, zero_division=0)
    prec_macro, rec_macro, f1_macro, _ = precision_recall_fscore_support(all_labels, all_preds, average='macro', zero_division=0)
    cm = confusion_matrix(all_labels, all_preds)
    return total_loss / total, acc, prec, rec, f1, prec_macro, rec_macro, f1_macro, cm, all_labels, all_preds

def measure_inference_time(model, dataloader, device="cuda", warmup=20, min_images=100):
    model.eval()
    model.to(device)

    # Flatten dataset menjadi list images
    imgs_list = []
    for imgs, labels in dataloader:
        for i in range(imgs.size(0)):
            imgs_list.append(imgs[i:i+1])
    with torch.no_grad():
        for i in range(min(warmup, len(imgs_list))):
            _ = model(imgs_list[i].to(device))

    # Pilih berapa gambar untuk inferensi
    N = min(min_images, len(imgs_list))

    torch.cuda.synchronize()
    start = time.time()

    with torch.no_grad():
        for i in range(N):
            _ = model(imgs_list[i].to(device))

    torch.cuda.synchronize()
    end = time.time()

    total_time = end - start
    avg_ms = (total_time / N) * 1000
    throughput = N / total_time

    return total_time, avg_ms, throughput

def main():
    print("Device:", DEVICE)
    df = read_label_file(LABEL_CSV)
    print("Label CSV head:\n", df.head())
    df, label2idx, idx2label = FoodDataset.encode_labels(df)
    global NUM_CLASSES
    NUM_CLASSES = len(label2idx)
    print("Detected classes:", label2idx)
    # create dataset object
    # map label to idx for dataset
    df_for_ds = df[['filename', 'label_idx']].rename(columns={'label_idx':'label'})
    df_for_ds = df_for_ds.sample(frac=1, random_state=RANDOM_SEED).reset_index(drop=True)

    dataset = FoodDataset(df_for_ds, DATA_DIR, transforms=train_transforms)
    # create train/val/test split 70/15/15
    n = len(dataset)
    if n < 20:
        raise ValueError("Dataset terlalu kecil untuk eksperimen (butuh >20 gambar).")
    n_train = int(0.7 * n)
    n_val = int(0.15 * n)
    n_test = n - n_train - n_val
    train_ds, val_ds, test_ds = random_split(dataset, [n_train, n_val, n_test], generator=torch.Generator().manual_seed(RANDOM_SEED))

    # override transforms for val/test
    train_ds.dataset.transforms = train_transforms
    val_ds.dataset.transforms = val_transforms
    test_ds.dataset.transforms = val_transforms

    train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)
    val_loader   = DataLoader(val_ds, batch_size=BATCH_SIZE, num_workers=2)
    test_loader  = DataLoader(test_ds, batch_size=BATCH_SIZE, num_workers=2)

    results_summary = {}

    for model_name in MODEL_NAMES:
        print("\n\n=== Training model:", model_name)
        model = timm.create_model(model_name, pretrained=True, num_classes=NUM_CLASSES)
        model.to(DEVICE)

        # optimizer
        optimizer = torch.optim.AdamW(model.parameters(), lr=LR)
        scheduler = None
        history = {"train_loss":[], "train_acc":[], "val_loss":[], "val_acc":[]}
        best_val_acc = 0.0
        best_state = None

        for epoch in range(1, NUM_EPOCHS+1):
            t0 = time.time()
            train_loss, train_acc = train_one_epoch(model, optimizer, scheduler, train_loader, DEVICE)
            val_loss, val_acc, _, _, _, _, _, _, _, _, _ = evaluate(model, val_loader, DEVICE)
            history["train_loss"].append(train_loss)
            history["train_acc"].append(train_acc)
            history["val_loss"].append(val_loss)
            history["val_acc"].append(val_acc)
            dt = time.time() - t0
            print(f"Epoch {epoch}/{NUM_EPOCHS} | train_loss={train_loss:.4f} acc={train_acc:.4f} | val_loss={val_loss:.4f} acc={val_acc:.4f} | time={dt:.1f}s")
            if val_acc > best_val_acc:
                best_val_acc = val_acc
                best_state = model.state_dict()
        # load best
        if best_state is not None:
            model.load_state_dict(best_state)

        # final evaluation on test
        test_loss, test_acc, prec, rec, f1, prec_macro, rec_macro, f1_macro, cm, all_labels, all_preds = evaluate(model, test_loader, DEVICE)

        # inference timing
        t_total, avg_ms, throughput = measure_inference_time(model, test_loader, DEVICE, warmup=20, min_images=100)

        # parameter counts and size
        total_params = sum(p.numel() for p in model.parameters())
        trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
        model_path = OUTPUT_DIR / f"{model_name.replace('/', '_')}_best.pth"
        torch.save(model.state_dict(), model_path)
        size_mb = model_path.stat().st_size / (1024*1024)

        # save results
        res = {
            "model_name": model_name,
            "total_params": int(total_params),
            "trainable_params": int(trainable_params),
            "model_size_mb": float(size_mb),
            "test_loss": float(test_loss),
            "test_acc": float(test_acc),
            "precision_per_class": prec.tolist(),
            "recall_per_class": rec.tolist(),
            "f1_per_class": f1.tolist(),
            "precision_macro": float(prec_macro),
            "recall_macro": float(rec_macro),
            "f1_macro": float(f1_macro),
            "confusion_matrix": cm.tolist(),
            "inference_total_time_s": float(t_total),
            "inference_avg_ms_per_image": float(avg_ms),
            "inference_throughput_fps": float(throughput),
            "hardware": DEVICE,
            "history": history,
            "label2idx": label2idx,
            "idx2label": idx2label,
            "test_size": len(test_ds),
        }
        results_summary[model_name] = res

        # save confusion matrix figure
        plt.figure(figsize=(6,5))
        sns.heatmap(np.array(cm), annot=True, fmt='d', xticklabels=[idx2label[i] for i in sorted(idx2label)], yticklabels=[idx2label[i] for i in sorted(idx2label)])
        plt.xlabel("Predicted")
        plt.ylabel("True")
        plt.title(f"Confusion Matrix: {model_name}")
        plt.tight_layout()
        plt.savefig(OUTPUT_DIR / f"{model_name}_confusion.png")
        plt.close()

        # save learning curves
        plt.figure()
        plt.plot(history["train_loss"], label="train_loss")
        plt.plot(history["val_loss"], label="val_loss")
        plt.legend(); plt.title(f"Loss Curves: {model_name}")
        plt.savefig(OUTPUT_DIR / f"{model_name}_loss.png")
        plt.close()

        plt.figure()
        plt.plot(history["train_acc"], label="train_acc")
        plt.plot(history["val_acc"], label="val_acc")
        plt.legend(); plt.title(f"Accuracy Curves: {model_name}")
        plt.savefig(OUTPUT_DIR / f"{model_name}_acc.png")
        plt.close()

        with open(OUTPUT_DIR / f"{model_name}_results.json", "w") as f:
            json.dump(res, f, indent=2)

    # save overall summary
    with open(OUTPUT_DIR / "summary_results.json", "w") as f:
        json.dump(results_summary, f, indent=2)

    print("All done. Results saved to", OUTPUT_DIR)

if __name__ == "__main__":
    main()

df = pd.read_csv(LABEL_CSV)
df = df.rename(columns={df.columns[0]:"filename", df.columns[1]:"label"})
labels_sorted = sorted(df["label"].unique())
label2idx = {l:i for i,l in enumerate(labels_sorted)}
df["label_idx"] = df["label"].map(label2idx)

val_tf = transforms.Compose([
    transforms.Resize((224,224)),
    transforms.ToTensor(),
    transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])
])

class FoodDataset(Dataset):
    def __init__(self, df, root, transform):
        self.df = df.reset_index(drop=True)
        self.root = Path(root)
        self.transform = transform
    def __len__(self):
        return len(self.df)
    def __getitem__(self, idx):
        row = self.df.iloc[idx]
        img = Image.open(self.root / row.filename).convert("RGB")
        return self.transform(img), row.label_idx

n = len(df)
train_n = int(0.7*n)
val_n = int(0.15*n)
test_n = n - train_n - val_n
df = df.sample(frac=1, random_state=42).reset_index(drop=True)

train_df = df[:train_n]
val_df   = df[train_n:train_n+val_n]
test_df  = df[train_n+val_n:]

test_ds = FoodDataset(test_df, DATA_DIR, val_tf)
test_loader = DataLoader(test_ds, batch_size=16, shuffle=False)

def measure_inference_time(model, dataloader, device="cuda", warmup=20, min_images=100):
    model.eval()
    model.to(device)

    imgs_list = []
    for imgs, labels in dataloader:
        for i in range(imgs.size(0)):
            imgs_list.append(imgs[i:i+1])

    with torch.no_grad():
        for i in range(min(warmup, len(imgs_list))):
            _ = model(imgs_list[i].to(device))

    N = min(min_images, len(imgs_list))

    torch.cuda.synchronize()
    import time
    start = time.time()
    with torch.no_grad():
        for i in range(N):
            _ = model(imgs_list[i].to(device))
    torch.cuda.synchronize()
    end = time.time()

    total = end - start
    avg_ms = (total / N) * 1000
    fps = N / total
    return total, avg_ms, fps

# RUN INFERENCE
MODELS = ["vit_base_patch16_224", "swin_tiny_patch4_window7_224"]
inference_results = {}

for name in MODELS:
    print(f"\n=== Inference: {name} ===")
    model = timm.create_model(name, pretrained=False, num_classes=len(label2idx))
    model.load_state_dict(torch.load(f"outputs/{name.replace('/', '_')}_best.pth", map_location=DEVICE))
    model.to(DEVICE)

    total_s, avg_ms, fps = measure_inference_time(model, test_loader, DEVICE)
    print(f"Total: {total_s:.4f} s")
    print(f"Avg per image: {avg_ms:.4f} ms")
    print(f"Throughput: {fps:.2f} img/s")

    inference_results[name] = {
        "total_s": total_s,
        "avg_ms": avg_ms,
        "fps": fps
    }

with open("outputs/inference_results.json", "w") as f:
    json.dump(inference_results, f, indent=2)

print("\nInference results saved â†’ outputs/inference_results.json")